{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8944f9b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rokey/git_package/cobot2/unit-tasks/Object_Detection\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13975b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "캡처 완료: ./capture6.png\n"
     ]
    }
   ],
   "source": [
    "import pyrealsense2 as rs\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# 정확한 상대 경로 지정\n",
    "save_path = \".\"\n",
    "os.makedirs(save_path, exist_ok=True)  # 폴더 없을 때만 생성\n",
    "filename = os.path.join(save_path, \"capture6.png\")\n",
    "# filename = os.path.join(save_path, \"capture2.png\")\n",
    "\n",
    "# RealSense 파이프라인 설정\n",
    "pipeline = rs.pipeline()\n",
    "config = rs.config()\n",
    "config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)\n",
    "\n",
    "# 카메라 실행 및 한 프레임 저장\n",
    "pipeline.start(config)\n",
    "try:\n",
    "    frames = pipeline.wait_for_frames()\n",
    "    color_frame = frames.get_color_frame()\n",
    "    if color_frame:\n",
    "        color_image = np.asanyarray(color_frame.get_data())\n",
    "        cv2.imwrite(filename, color_image)\n",
    "        print(f\"캡처 완료: {filename}\")\n",
    "    else:\n",
    "        print(\"프레임을 가져올 수 없습니다.\")\n",
    "finally:\n",
    "    pipeline.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b034d8af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 캡처 완료: ./capture5.png\n"
     ]
    }
   ],
   "source": [
    "## 캡처할 때 부터 이미지 개선\n",
    "import pyrealsense2 as rs\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# 저장 경로\n",
    "save_path = \".\"\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "filename = os.path.join(save_path, \"capture5.png\")\n",
    "\n",
    "# RealSense 파이프라인 설정\n",
    "pipeline = rs.pipeline()\n",
    "config = rs.config()\n",
    "config.enable_stream(rs.stream.color, 1280, 720, rs.format.bgr8, 30)  # 더 높은 해상도\n",
    "\n",
    "# 파이프라인 시작\n",
    "profile = pipeline.start(config)\n",
    "device = profile.get_device()\n",
    "color_sensor = device.query_sensors()[1]  # 보통 컬러 센서는 index 1\n",
    "\n",
    "\n",
    "#수동 튜닝\n",
    "color_sensor.set_option(rs.option.enable_auto_exposure, 0)  # 자동 노출 끄기\n",
    "\n",
    "color_sensor.set_option(rs.option.exposure, 70)           # 이전보다 약간 올려서 더 밝게\n",
    "color_sensor.set_option(rs.option.brightness, 25)         # 미세 조정\n",
    "color_sensor.set_option(rs.option.contrast, 60)           # ✅ contrast 줄임\n",
    "color_sensor.set_option(rs.option.gamma, 200)             # ✅ gamma 줄임\n",
    "color_sensor.set_option(rs.option.saturation, 60)         # 색 너무 세지 않도록\n",
    "color_sensor.set_option(rs.option.white_balance, 4700)    # 약간 따뜻하게\n",
    "\n",
    "\n",
    "# 안정적인 프레임 확보 후 캡처\n",
    "try:\n",
    "    for _ in range(10):  # warm-up\n",
    "        frames = pipeline.wait_for_frames()\n",
    "    color_frame = frames.get_color_frame()\n",
    "\n",
    "    if color_frame:\n",
    "        color_image = np.asanyarray(color_frame.get_data())\n",
    "        cv2.imwrite(filename, color_image)\n",
    "        print(f\"✅ 캡처 완료: {filename}\")\n",
    "    else:\n",
    "        print(\"❌ 컬러 프레임을 가져오지 못했습니다.\")\n",
    "finally:\n",
    "    pipeline.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27dd76b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "brightness           : min=-64.0, max=64.0, default=0.0, step=1.0\n",
      "contrast             : min=0.0, max=100.0, default=50.0, step=1.0\n",
      "saturation           : min=0.0, max=100.0, default=64.0, step=1.0\n",
      "exposure             : min=1.0, max=10000.0, default=166.0, step=1.0\n",
      "white_balance        : min=2800.0, max=6500.0, default=4600.0, step=10.0\n",
      "sharpness            : min=0.0, max=100.0, default=50.0, step=1.0\n",
      "gamma                : min=100.0, max=500.0, default=300.0, step=1.0\n"
     ]
    }
   ],
   "source": [
    "## 참고 카메라 밝기 확인\n",
    "def print_sensor_range(sensor):\n",
    "    for opt in [rs.option.brightness, rs.option.contrast, rs.option.saturation,\n",
    "                rs.option.exposure, rs.option.white_balance, rs.option.sharpness, rs.option.gamma]:\n",
    "        if sensor.supports(opt):\n",
    "            r = sensor.get_option_range(opt)\n",
    "            print(f\"{opt.name:20} : min={r.min}, max={r.max}, default={r.default}, step={r.step}\")\n",
    "\n",
    "print_sensor_range(color_sensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "865a3659",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 전처리\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def enhance_contrast_for_detection(image):\n",
    "    # 감마 보정 (살짝 밝게)\n",
    "    gamma = 1.3\n",
    "    inv_gamma = 1.0 / gamma\n",
    "    table = np.array([(i / 255.0) ** inv_gamma * 255 for i in range(256)]).astype(\"uint8\")\n",
    "    gamma_corrected = cv2.LUT(image, table)\n",
    "\n",
    "    # LAB 기반 CLAHE로 국소 대비 향상\n",
    "    lab = cv2.cvtColor(gamma_corrected, cv2.COLOR_BGR2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.5, tileGridSize=(8, 8))\n",
    "    cl = clahe.apply(l)\n",
    "    merged = cv2.merge((cl, a, b))\n",
    "    final = cv2.cvtColor(merged, cv2.COLOR_LAB2BGR)\n",
    "    return final\n",
    "\n",
    "\n",
    "def sharpen_image(image):\n",
    "    \"\"\"\n",
    "    윤곽을 강조하는 샤프닝 필터 적용\n",
    "    \"\"\"\n",
    "    kernel = np.array([[0, -1, 0],\n",
    "                       [-1, 5, -1],\n",
    "                       [0, -1, 0]])  # 기본 sharpening kernel\n",
    "    return cv2.filter2D(image, -1, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90bf7ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 2 hammers, 1 wrench, 281.1ms\n",
      "Speed: 4.1ms preprocess, 281.1ms inference, 5.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict4\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "## 전처리 + 테스트\n",
    "\n",
    "img = cv2.imread(\"capture.png\")\n",
    "# 전처리 적용\n",
    "enhanced = enhance_contrast_for_detection(img)\n",
    "\n",
    "# (선택) 샤프닝 추가\n",
    "enhanced = sharpen_image(enhanced)\n",
    "\n",
    "# YOLO 예측\n",
    "from ultralytics import YOLO\n",
    "model = YOLO(\"/home/kiwi/github_package/cobot2/unit-tasks/Object_Detection/yolo8_2.pt\")\n",
    "results = model.predict(enhanced, conf=0.25, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b6fa0b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 hammers, 1 wrench, 237.8ms\n",
      "Speed: 2.0ms preprocess, 237.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict18\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "## 노랑배경 흰색으로\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def replace_yellow_background_with_white(image_bgr):\n",
    "    hsv = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # 더 좁은 노란색 범위\n",
    "    lower_yellow = np.array([22, 100, 100])\n",
    "    upper_yellow = np.array([32, 255, 255])\n",
    "    \n",
    "    mask = cv2.inRange(hsv, lower_yellow, upper_yellow)\n",
    "    result = image_bgr.copy()\n",
    "    result[mask > 0] = [255, 255, 255]\n",
    "    return result\n",
    "\n",
    "\n",
    "img = cv2.imread(\"capture5.png\")\n",
    "processed_bgr = replace_yellow_background_with_white(img)\n",
    "\n",
    "# 3. BGR → RGB 변환 (YOLO는 RGB 입력)\n",
    "processed_rgb = cv2.cvtColor(processed_bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# 4. YOLO 모델 불러오기\n",
    "model = YOLO(\"/home/kiwi/github_package/cobot2/unit-tasks/Object_Detection/yolo8_2.pt\")\n",
    "\n",
    "# 5. 예측 (save=False로 저장 생략)\n",
    "results = model.predict(source=processed_rgb, save=True, save_txt=False, conf=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85cf4f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/kiwi/github_package/cobot2/unit-tasks/Object_Detection/capture6.png: 480x640 1 hammer, 1 wrench, 295.6ms\n",
      "Speed: 4.7ms preprocess, 295.6ms inference, 9.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict20\u001b[0m\n",
      "1 label saved to runs/detect/predict20/labels\n"
     ]
    }
   ],
   "source": [
    "## 이미지 테스트 yolo8\n",
    "# /content/runs/detect/predict/  ← 결과 이미지 (.jpg) 및 .txt 파일\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# 모델 로드\n",
    "model = YOLO(\"/home/kiwi/github_package/cobot2/unit-tasks/Object_Detection/yolo8_2.pt\")\n",
    "# 예측 실행\n",
    "results = model.predict(\n",
    "    source=\"/home/kiwi/github_package/cobot2/unit-tasks/Object_Detection/capture6.png\",\n",
    "    save=True,      # 결과 이미지 저장\n",
    "    save_txt=True,  # 라벨 텍스트 저장 (optional)\n",
    "    conf=0.25        # confidence threshold (기본값은 0.25)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d6d2df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/rokey/git_package/cobot2/unit-tasks/Object_Detection/capture6.png: 480x640 1 hammer, 1 screwdriver, 1 wrench, 77.8ms\n",
      "Speed: 1.0ms preprocess, 77.8ms inference, 64.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict19\u001b[0m\n",
      "1 label saved to runs/detect/predict19/labels\n"
     ]
    }
   ],
   "source": [
    "## 이미지 테스트 yolo11\n",
    "# /content/runs/detect/predict/  ← 결과 이미지 (.jpg) 및 .txt 파일\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# 모델 로드\n",
    "model = YOLO(\"/home/rokey/git_package/cobot2/unit-tasks/Object_Detection/yolo11_1.pt\")\n",
    "\n",
    "# 예측 실행\n",
    "results = model.predict(\n",
    "    source=\"/home/rokey/git_package/cobot2/unit-tasks/Object_Detection/capture6.png\",\n",
    "    save=True,      # 결과 이미지 저장\n",
    "    save_txt=True,  # 라벨 텍스트 저장 (optional)\n",
    "    conf=0.25        # confidence threshold (기본값은 0.25)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c160ee72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
